import streamlit as st
from langchain_google_genai import GoogleGenerativeAIEmbeddings, ChatGoogleGenerativeAI
from langchain_community.document_loaders import PyPDFLoader
from langchain_community.vectorstores import FAISS
from langchain.text_splitter import RecursiveCharacterTextSplitter
from langchain.chains import ConversationalRetrievalChain
from langchain.memory import ConversationBufferMemory
from langchain.prompts import PromptTemplate
import os

# 1. í˜ì´ì§€ ì„¤ì • ë° iMessage ìŠ¤íƒ€ì¼ CSS
st.set_page_config(page_title="iOS Chatbot", page_icon="ğŸ’¬")

st.markdown("""
<style>
    .stApp { background-color: #ffffff; }
    .chat-bubble {
        padding: 10px 15px;
        border-radius: 20px;
        margin: 5px 0;
        max-width: 70%;
        font-family: -apple-system, sans-serif;
        font-size: 15px;
        line-height: 1.4;
    }
    .user-bubble {
        background-color: #007aff;
        color: white;
        align-self: flex-end;
        border-bottom-right-radius: 2px;
    }
    .bot-bubble {
        background-color: #e9e9eb;
        color: black;
        align-self: flex-start;
        border-bottom-left-radius: 2px;
    }
    .chat-row { display: flex; flex-direction: column; }
    [data-testid="stChatMessageAvatarBackground"] { display: none; }
</style>
""", unsafe_allow_html=True)

# API ë³´ì•ˆ ì„¤ì •
if "GEMINI_API_KEY" not in st.secrets:
    st.error("Streamlit Cloud ì„¤ì •ì—ì„œ 'GEMINI_API_KEY'ë¥¼ ì¶”ê°€í•´ì£¼ì„¸ìš”.")
    st.stop()
os.environ["GOOGLE_API_KEY"] = st.secrets["GEMINI_API_KEY"]

# 2. RAG ì—”ì§„ (ìµœì‹  Gemini 2.5 Flash ë° ì—„ê²© í”„ë¡¬í”„íŠ¸)
@st.cache_resource
def init_rag():
    if not os.path.exists("test.pdf"):
        return None
    loader = PyPDFLoader("test.pdf")
    docs = loader.load()
    splits = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=100).split_documents(docs)
    vectorstore = FAISS.from_documents(splits, GoogleGenerativeAIEmbeddings(model="models/text-embedding-004"))
    
    # [í•„ìˆ˜] gemini-2.5-flash ëª¨ë¸ ì‚¬ìš©
    llm = ChatGoogleGenerativeAI(model="gemini-2.5-flash", temperature=0)

    template = """ë‹¹ì‹ ì€ ì œê³µëœ ë¬¸ì„œë¥¼ ê¸°ë°˜ìœ¼ë¡œ ë‹µë³€í•˜ëŠ” ë¹„ì„œì…ë‹ˆë‹¤.
    ê·œì¹™:
    1. ë°˜ë“œì‹œ ì œê³µëœ ì»¨í…ìŠ¤íŠ¸(Context) ë‚´ìš©ë§Œ ì°¸ê³ í•˜ì„¸ìš”.
    2. ë¬¸ì„œì— ì—†ëŠ” ë‚´ìš©ì´ë¼ë©´ "ì£„ì†¡í•©ë‹ˆë‹¤. í•´ë‹¹ ì •ë³´ëŠ” ë¬¸ì„œì—ì„œ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤."ë¼ê³ ë§Œ ë‹µí•˜ì„¸ìš”.
    3. ì™¸ë¶€ ì§€ì‹ì„ ì ˆëŒ€ ì‚¬ìš©í•˜ì§€ ë§ˆì„¸ìš”.

    Context: {context}
    Question: {question}
    Answer:"""
    
    memory = ConversationBufferMemory(memory_key="chat_history", return_messages=True)
    return ConversationalRetrievalChain.from_llm(
        llm=llm,
        retriever=vectorstore.as_retriever(),
        memory=memory,
        combine_docs_chain_kwargs={"prompt": PromptTemplate(template=template, input_variables=["context", "question"])}
    )

chain = init_rag()

# 3. ì±„íŒ… UI êµ¬í˜„
if "messages" not in st.session_state:
    st.session_state.messages = []

for msg in st.session_state.messages:
    align = "flex-end" if msg["role"] == "user" else "flex-start"
    bubble_type = "user-bubble" if msg["role"] == "user" else "bot-bubble"
    st.markdown(f'<div style="display: flex; flex-direction: column; align-items: {align};"><div class="chat-bubble {bubble_type}">{msg["content"]}</div></div>', unsafe_allow_html=True)

if prompt := st.chat_input("ë©”ì‹œì§€ë¥¼ ì…ë ¥í•˜ì„¸ìš”..."):
    st.markdown(f'<div style="display: flex; flex-direction: column; align-items: flex-end;"><div class="chat-bubble user-bubble">{prompt}</div></div>', unsafe_allow_html=True)
    st.session_state.messages.append({"role": "user", "content": prompt})
    
    if chain:
        with st.spinner(""):
            res = chain.invoke({"question": prompt})
            ans = res['answer']
            st.markdown(f'<div style="display: flex; flex-direction: column; align-items: flex-start;"><div class="chat-bubble bot-bubble">{ans}</div></div>', unsafe_allow_html=True)
            st.session_state.messages.append({"role": "assistant", "content": ans})
    else:
        st.error("test.pdf íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤.")
